<img src="/heARLogo.png" width="400" height="200" />

# heAR - Richard Gao, Mustafa Eyceoz, James Ma, Joanne Lyu, and Devanshi Udeshi
Revolutionizing human communication for the Hearing Impaired. <br/>
App developed for the Magic Leap One Mixed Reality Headset.

# Features
-Intuitive interface for speech to text conversion. <br/>
  -Create speech bubbles for text reading through easy controller input.  <br/>
  -Instructions for use included on UI.  <br/>
  -Speech log (history of what has been said) is recorded and displayed on UI.  <br/>
  -UI can be hidden on demand for minimal intrusion.  <br/>
-Can capture and translate sign language gestures instantly at the press of a button.  <br/>
-Uses machine learning to train model to convert ASL sign language to text.  <br/>

# How it Was Built
-Magic Leap SDK for Unity and Lumin SDK to build the AR experience, including space scanning, object overlaying for our speech bubbles and ray-casting for human recognition.  <br/>
-IBM Watson API and Watson's Unity SDK for speech to text recognition, and a custom CNN for gesture / sign language recognition.  <br/>
-We host CNN on Google Cloud Services and use Restful API to communicate with the server.  <br/>
-AfterEffect, Illustrator, C4D, and Blender to build custom assets and animation.  <br/>
